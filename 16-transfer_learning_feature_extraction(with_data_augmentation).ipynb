{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhYV_qGj0tb6",
        "outputId": "fb74c0f6-0ccc-4767-b546-1d027b1ed55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9qTnfyU-iGm",
        "outputId": "e8f2d87b-61ee-4aee-9c17-87fcc29e3d5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.6.14)\n",
            "Dataset URL: https://www.kaggle.com/datasets/salader/dogs-vs-cats\n",
            "License(s): unknown\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 1.06G/1.06G [00:10<00:00, 228MB/s]\n",
            "100% 1.06G/1.06G [00:10<00:00, 111MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "EbpCiQEr-jfl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "oxsbyMT0-lP8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top = False,\n",
        "    input_shape=(150,150,3)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWhGLNEJ-nIB",
        "outputId": "4ace504b-8342-4bd5-e8a2-1d3880774448"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHIDyPRv_X8W",
        "outputId": "c55740d3-2a74-4bc6-9433-4af3639d96fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "ZL_fmHXX-qpU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOwNU56l_atn",
        "outputId": "fa02215b-c4b3-4049-a018-acbb281123a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16812353 (64.13 MB)\n",
            "Trainable params: 16812353 (64.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "xin1EE3S-vha"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation\n",
        "batch_size = 32\n",
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img,load_img\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train',\n",
        "    target_size=(150,150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/test',\n",
        "    target_size=(150,150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9njEWIUk-xUW",
        "outputId": "0b317d2f-2ed8-4a6e-cf1b-40603e704157"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KD7ovmeBBoPQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGBJfmeJBpyG",
        "outputId": "11cec82c-1eed-48a2-b1d7-27caf4e0a5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 164s 250ms/step - loss: 0.3050 - accuracy: 0.8668 - val_loss: 0.2166 - val_accuracy: 0.9048\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 153s 246ms/step - loss: 0.2423 - accuracy: 0.8967 - val_loss: 0.2037 - val_accuracy: 0.9112\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 153s 245ms/step - loss: 0.2270 - accuracy: 0.9010 - val_loss: 0.1956 - val_accuracy: 0.9160\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 154s 246ms/step - loss: 0.2031 - accuracy: 0.9128 - val_loss: 0.2017 - val_accuracy: 0.9116\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 154s 247ms/step - loss: 0.2034 - accuracy: 0.9122 - val_loss: 0.1849 - val_accuracy: 0.9186\n",
            "Epoch 6/10\n",
            " 17/625 [..............................] - ETA: 2:21 - loss: 0.1566 - accuracy: 0.9265"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'],color='red',label='train')\n",
        "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "klF1C48OBrF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss\n",
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "veiDL-rxB8F-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}